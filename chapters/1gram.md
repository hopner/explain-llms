# The 1-gram model

**Learning objective:** How simple statistical models can generate text.

Content table:
| Step | Content | Animation |
|---|---:|---|
| 1 | The AI reads text without understanding the meaning | "The cat sat on the mat." is "read" by the model |
| 2 | The AI counts how often each word appears | A bar chart shows word frequencies |
| 3 | Estimate the probability of each word | Bars are converted to a histogram |
| 4 | The model select the highest probability word | Given a prompt, the model picks the most likely next word |
| 5 | This quickly becomes repetitive, deterministic, too simple to capture context | Generated text is "the the the the..." |
| 6 | frequency matters, but words alone arenâ€™t enough to make language meaningful | Comparison between the generated text and human written text |
